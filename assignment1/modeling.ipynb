{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de6e7733",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.2' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# cross-validation \n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "# classification models \n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, roc_curve \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# cox model \n",
    "from lifelines import CoxPHFitter\n",
    "from lifelines.utils import concordance_index\n",
    "\n",
    "# mlp\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b53872a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>anaemia</th>\n",
       "      <th>creatinine_phosphokinase</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>ejection_fraction</th>\n",
       "      <th>high_blood_pressure</th>\n",
       "      <th>platelets</th>\n",
       "      <th>serum_creatinine</th>\n",
       "      <th>serum_sodium</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoking</th>\n",
       "      <th>time</th>\n",
       "      <th>DEATH_EVENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>374000.00</td>\n",
       "      <td>0.80</td>\n",
       "      <td>140</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>434</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>268112.43</td>\n",
       "      <td>1.21</td>\n",
       "      <td>135</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>138</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>185000.00</td>\n",
       "      <td>1.10</td>\n",
       "      <td>134</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>208</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>216218.24</td>\n",
       "      <td>0.98</td>\n",
       "      <td>134</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>235</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>329000.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>142</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>748</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>263000.00</td>\n",
       "      <td>1.30</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>582</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>263358.03</td>\n",
       "      <td>1.60</td>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>244</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>838</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>304117.75</td>\n",
       "      <td>0.80</td>\n",
       "      <td>133</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>405514.68</td>\n",
       "      <td>1.11</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>209</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>898</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>149000.00</td>\n",
       "      <td>1.10</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>900 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  anaemia  creatinine_phosphokinase  diabetes  ejection_fraction  \\\n",
       "0     41        0                       148         0                 40   \n",
       "1     66        0                       434         1                 24   \n",
       "2     70        0                        93         0                 35   \n",
       "3     72        0                       140         1                 50   \n",
       "4     60        0                       235         1                 38   \n",
       "..   ...      ...                       ...       ...                ...   \n",
       "895   55        0                       748         0                 45   \n",
       "896   44        0                       582         1                 30   \n",
       "897   70        0                       838         1                 35   \n",
       "898   77        0                       107         0                 50   \n",
       "899   80        0                       898         0                 25   \n",
       "\n",
       "     high_blood_pressure  platelets  serum_creatinine  serum_sodium  sex  \\\n",
       "0                      0  374000.00              0.80           140    1   \n",
       "1                      1  268112.43              1.21           135    1   \n",
       "2                      0  185000.00              1.10           134    1   \n",
       "3                      0  216218.24              0.98           134    1   \n",
       "4                      0  329000.00              3.00           142    0   \n",
       "..                   ...        ...               ...           ...  ...   \n",
       "895                    0  263000.00              1.30           137    1   \n",
       "896                    1  263358.03              1.60           130    1   \n",
       "897                    1  304117.75              0.80           133    1   \n",
       "898                    1  405514.68              1.11           137    1   \n",
       "899                    0  149000.00              1.10           144    1   \n",
       "\n",
       "     smoking  time  DEATH_EVENT  \n",
       "0          1    68            0  \n",
       "1          1   138            1  \n",
       "2          1   208            0  \n",
       "3          0    32            0  \n",
       "4          0    30            1  \n",
       "..       ...   ...          ...  \n",
       "895        0    88            0  \n",
       "896        1   244            0  \n",
       "897        0   144            1  \n",
       "898        1   209            1  \n",
       "899        1    87            0  \n",
       "\n",
       "[900 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = './heart_failure_dataset.csv' # This line assumes the csv file to be placed in the current working directory \n",
    "                                          # To be changed if it was placed somewhere else \n",
    "df = pd.read_csv(data_path, index_col=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b83cd53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'DEATH_EVENT': 'event', 'time': 'time'})\n",
    "\n",
    "# Prepare the input features and target variable\n",
    "X = df.drop(columns=['time', 'event'])\n",
    "y = df['event']  # Target variable (renamed DEATH_EVENT)\n",
    "time = df['time']\n",
    "y_with_time = pd.DataFrame({'event': y, 'time': time})\n",
    "\n",
    "# Performing an 80/20 train-test split, stratified by 'event'\n",
    "X_dev, X_test, y_dev_with_time, y_test_with_time = train_test_split(X, y_with_time, test_size=0.2, stratify=y, random_state=42)\n",
    "y_dev = y_dev_with_time['event']\n",
    "time_dev = y_dev_with_time['time']\n",
    "y_test = y_test_with_time['event']\n",
    "time_test = y_test_with_time['time']\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03acb7d7",
   "metadata": {},
   "source": [
    "# Logistic regression with l2 (ridge) regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "88915aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regularization strength: 0.0001\n",
      "Regularization strength: 0.001\n",
      "Regularization strength: 0.01\n",
      "Regularization strength: 0.1\n",
      "Regularization strength: 1\n",
      "Regularization strength: 10\n",
      "Regularization strength: 100\n",
      "Best hyperparams: 0.001\n",
      "Best AUROC: 0.6862 (0.0249)\n",
      "Best hyperparameters: C = 0.001\n",
      "Accuracy: Mean = 0.6292 (0.0136)\n",
      "Precision: Mean = 0.6194 (0.0120)\n",
      "Recall: Mean = 0.6859 (0.0222)\n",
      "F1-Score: Mean = 0.6509 (0.0147)\n",
      "AUROC: Mean = 0.6862 (0.0249)\n",
      "AUPRC: Mean = 0.6911 (0.0359)\n"
     ]
    }
   ],
   "source": [
    "# Track the best results\n",
    "best_auroc_mean = 0\n",
    "best_auroc_std = 0\n",
    "best_metrics = None\n",
    "best_hyperparams = None\n",
    "\n",
    "for C in [0.0001, 0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "    print(f\"Regularization strength: {C}\")\n",
    "    # Initialize lists to store the metrics for each fold\n",
    "    accuracy_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    f1_scores = []\n",
    "    auroc_scores = []\n",
    "    auprc_scores = []\n",
    "    # Perform 5-fold cross-validation\n",
    "    for train_index, val_index in kf.split(X_dev, y_dev):\n",
    "        # get train and val data \n",
    "        X_train_fold, X_val_fold = X_dev.iloc[train_index], X_dev.iloc[val_index]\n",
    "        y_train_fold, y_val_fold = y_dev.iloc[train_index], y_dev.iloc[val_index]\n",
    "\n",
    "        # Normalize the training set and apply the same params to val\n",
    "        scaler = StandardScaler()\n",
    "        X_train_fold_scaled = scaler.fit_transform(X_train_fold)\n",
    "        X_val_fold_scaled = scaler.transform(X_val_fold)\n",
    "\n",
    "        # fit logistic regression model \n",
    "        log_reg = LogisticRegression(max_iter=1000, random_state=42, C=C, penalty='l2')\n",
    "        log_reg.fit(X_train_fold_scaled, y_train_fold)\n",
    "\n",
    "        # evaluate on val \n",
    "        y_val_pred = log_reg.predict(X_val_fold_scaled)\n",
    "        y_val_prob = log_reg.predict_proba(X_val_fold_scaled)[:, 1]  # Probabilities for positive class\n",
    "\n",
    "        # Calculate and store classification metrics\n",
    "        accuracy_scores.append(accuracy_score(y_val_fold, y_val_pred))\n",
    "        precision_scores.append(precision_score(y_val_fold, y_val_pred))\n",
    "        recall_scores.append(recall_score(y_val_fold, y_val_pred))\n",
    "        f1_scores.append(f1_score(y_val_fold, y_val_pred))\n",
    "        auroc_scores.append(roc_auc_score(y_val_fold, y_val_prob))\n",
    "        auprc_scores.append(average_precision_score(y_val_fold, y_val_prob))\n",
    "\n",
    "    # Calculate mean and standard deviation of AUROC\n",
    "    auroc_mean = np.mean(auroc_scores)\n",
    "    auroc_std = np.std(auroc_scores)\n",
    "\n",
    "    # Check if this is the best AUROC so far\n",
    "    if auroc_mean > best_auroc_mean:\n",
    "        best_auroc_mean = auroc_mean\n",
    "        best_auroc_std = auroc_std\n",
    "        best_metrics = {\n",
    "            'accuracy': (np.mean(accuracy_scores), np.std(accuracy_scores)),\n",
    "            'precision': (np.mean(precision_scores), np.std(precision_scores)),\n",
    "            'recall': (np.mean(recall_scores), np.std(recall_scores)),\n",
    "            'f1_score': (np.mean(f1_scores), np.std(f1_scores)),\n",
    "            'auroc': (auroc_mean, auroc_std),\n",
    "            'auprc': (np.mean(auprc_scores), np.std(auprc_scores))\n",
    "        }\n",
    "        best_hyperparams = C\n",
    "\n",
    "# Print the best results\n",
    "print(f\"Best hyperparams: {best_hyperparams}\")\n",
    "print(f\"Best AUROC: {best_metrics['auroc'][0]:.4f} ({best_metrics['auroc'][1]:.4f})\")\n",
    "print(f\"Best hyperparameters: C = {best_hyperparams}\")\n",
    "print(f\"Accuracy: Mean = {best_metrics['accuracy'][0]:.4f} ({best_metrics['accuracy'][1]:.4f})\")\n",
    "print(f\"Precision: Mean = {best_metrics['precision'][0]:.4f} ({best_metrics['precision'][1]:.4f})\")\n",
    "print(f\"Recall: Mean = {best_metrics['recall'][0]:.4f} ({best_metrics['recall'][1]:.4f})\")\n",
    "print(f\"F1-Score: Mean = {best_metrics['f1_score'][0]:.4f} ({best_metrics['f1_score'][1]:.4f})\")\n",
    "print(f\"AUROC: Mean = {best_metrics['auroc'][0]:.4f} ({best_metrics['auroc'][1]:.4f})\")\n",
    "print(f\"AUPRC: Mean = {best_metrics['auprc'][0]:.4f} ({best_metrics['auprc'][1]:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3079f7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.7111\n",
      "Precision on test set: 0.7349\n",
      "Recall on test set: 0.6703\n",
      "F1-Score on test set: 0.7011\n",
      "AUROC on test set: 0.7715\n",
      "AUPRC on test set: 0.7541\n"
     ]
    }
   ],
   "source": [
    "# After determining the best hyperparameter 'C' from cross-validation:\n",
    "best_C = best_hyperparams  # This is the best 'C' found during cross-validation\n",
    "\n",
    "# Normalize the entire development set and the test set\n",
    "scaler = StandardScaler()\n",
    "X_dev_scaled = scaler.fit_transform(X_dev)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Prepare development and test data\n",
    "train_data = pd.DataFrame(X_dev_scaled, columns=X.columns)\n",
    "train_data['time'] = time_dev.values\n",
    "train_data['event'] = y_dev.values\n",
    "test_data = pd.DataFrame(X_test_scaled, columns=X.columns)\n",
    "test_data['time'] = time_test.values\n",
    "test_data['event'] = y_test.values\n",
    "\n",
    "# fit logistic regression model \n",
    "log_reg = LogisticRegression(max_iter=1000, random_state=42, C=C, penalty='l2')\n",
    "log_reg.fit(X_dev_scaled, y_dev)\n",
    "\n",
    "# evaluate on val \n",
    "y_test_pred = log_reg.predict(X_test_scaled)\n",
    "y_test_prob = log_reg.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Calculate ROC curve and Youden's index for the test set\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_test_prob)\n",
    "\n",
    "# Calculate classification metrics on the test set\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "precision_test = precision_score(y_test, y_test_pred)\n",
    "recall_test = recall_score(y_test, y_test_pred)\n",
    "f1_test = f1_score(y_test, y_test_pred)\n",
    "auroc_test = roc_auc_score(y_test, y_test_prob)\n",
    "auprc_test = average_precision_score(y_test, y_test_prob)\n",
    "\n",
    "# Print the test set performance\n",
    "print(f\"Accuracy on test set: {accuracy_test:.4f}\")\n",
    "print(f\"Precision on test set: {precision_test:.4f}\")\n",
    "print(f\"Recall on test set: {recall_test:.4f}\")\n",
    "print(f\"F1-Score on test set: {f1_test:.4f}\")\n",
    "print(f\"AUROC on test set: {auroc_test:.4f}\")\n",
    "print(f\"AUPRC on test set: {auprc_test:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8865f4a",
   "metadata": {},
   "source": [
    "# Logistic regression with l1 (LASSO) regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "43d7a7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regularization strength: 0.0001\n",
      "Regularization strength: 0.001\n",
      "Regularization strength: 0.01\n",
      "Regularization strength: 0.1\n",
      "Regularization strength: 1\n",
      "Regularization strength: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regularization strength: 100\n",
      "Best hyperparams: 100\n",
      "Best AUROC: 0.6821 (0.0220)\n",
      "Best hyperparameters: C = 100\n",
      "Accuracy: Mean = 0.6292 (0.0231)\n",
      "Precision: Mean = 0.6324 (0.0234)\n",
      "Recall: Mean = 0.6336 (0.0390)\n",
      "F1-Score: Mean = 0.6324 (0.0248)\n",
      "AUROC: Mean = 0.6821 (0.0220)\n",
      "AUPRC: Mean = 0.6814 (0.0289)\n"
     ]
    }
   ],
   "source": [
    "# Track the best results\n",
    "best_auroc_mean = 0\n",
    "best_auroc_std = 0\n",
    "best_metrics = None\n",
    "best_hyperparams = None\n",
    "\n",
    "for C in [0.0001, 0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "    print(f\"Regularization strength: {C}\")\n",
    "    # Initialize lists to store the metrics for each fold\n",
    "    accuracy_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    f1_scores = []\n",
    "    auroc_scores = []\n",
    "    auprc_scores = []\n",
    "    # Perform 5-fold cross-validation\n",
    "    for train_index, val_index in kf.split(X_dev, y_dev):\n",
    "        # get train and val data \n",
    "        X_train_fold, X_val_fold = X_dev.iloc[train_index], X_dev.iloc[val_index]\n",
    "        y_train_fold, y_val_fold = y_dev.iloc[train_index], y_dev.iloc[val_index]\n",
    "\n",
    "        # Normalize the training set and apply the same params to val\n",
    "        scaler = StandardScaler()\n",
    "        X_train_fold_scaled = scaler.fit_transform(X_train_fold)\n",
    "        X_val_fold_scaled = scaler.transform(X_val_fold)\n",
    "\n",
    "        # fit logistic regression model \n",
    "        log_reg = LogisticRegression(max_iter=1000, random_state=42, C=C, penalty='l1', solver='saga')\n",
    "        log_reg.fit(X_train_fold_scaled, y_train_fold)\n",
    "\n",
    "        # evaluate on val \n",
    "        y_val_pred = log_reg.predict(X_val_fold_scaled)\n",
    "        y_val_prob = log_reg.predict_proba(X_val_fold_scaled)[:, 1]  # Probabilities for positive class\n",
    "\n",
    "        # Calculate and store classification metrics\n",
    "        accuracy_scores.append(accuracy_score(y_val_fold, y_val_pred))\n",
    "        precision_scores.append(precision_score(y_val_fold, y_val_pred))\n",
    "        recall_scores.append(recall_score(y_val_fold, y_val_pred))\n",
    "        f1_scores.append(f1_score(y_val_fold, y_val_pred))\n",
    "        auroc_scores.append(roc_auc_score(y_val_fold, y_val_prob))\n",
    "        auprc_scores.append(average_precision_score(y_val_fold, y_val_prob))\n",
    "\n",
    "    # Calculate mean and standard deviation of AUROC\n",
    "    auroc_mean = np.mean(auroc_scores)\n",
    "    auroc_std = np.std(auroc_scores)\n",
    "\n",
    "    # Check if this is the best AUROC so far\n",
    "    if auroc_mean > best_auroc_mean:\n",
    "        best_auroc_mean = auroc_mean\n",
    "        best_auroc_std = auroc_std\n",
    "        best_metrics = {\n",
    "            'accuracy': (np.mean(accuracy_scores), np.std(accuracy_scores)),\n",
    "            'precision': (np.mean(precision_scores), np.std(precision_scores)),\n",
    "            'recall': (np.mean(recall_scores), np.std(recall_scores)),\n",
    "            'f1_score': (np.mean(f1_scores), np.std(f1_scores)),\n",
    "            'auroc': (auroc_mean, auroc_std),\n",
    "            'auprc': (np.mean(auprc_scores), np.std(auprc_scores))\n",
    "        }\n",
    "        best_hyperparams = C\n",
    "\n",
    "# Print the best results\n",
    "print(f\"Best hyperparams: {best_hyperparams}\")\n",
    "print(f\"Best AUROC: {best_metrics['auroc'][0]:.4f} ({best_metrics['auroc'][1]:.4f})\")\n",
    "print(f\"Best hyperparameters: C = {best_hyperparams}\")\n",
    "print(f\"Accuracy: Mean = {best_metrics['accuracy'][0]:.4f} ({best_metrics['accuracy'][1]:.4f})\")\n",
    "print(f\"Precision: Mean = {best_metrics['precision'][0]:.4f} ({best_metrics['precision'][1]:.4f})\")\n",
    "print(f\"Recall: Mean = {best_metrics['recall'][0]:.4f} ({best_metrics['recall'][1]:.4f})\")\n",
    "print(f\"F1-Score: Mean = {best_metrics['f1_score'][0]:.4f} ({best_metrics['f1_score'][1]:.4f})\")\n",
    "print(f\"AUROC: Mean = {best_metrics['auroc'][0]:.4f} ({best_metrics['auroc'][1]:.4f})\")\n",
    "print(f\"AUPRC: Mean = {best_metrics['auprc'][0]:.4f} ({best_metrics['auprc'][1]:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "160068ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.7111\n",
      "Precision on test set: 0.7349\n",
      "Recall on test set: 0.6703\n",
      "F1-Score on test set: 0.7011\n",
      "AUROC on test set: 0.7715\n",
      "AUPRC on test set: 0.7541\n"
     ]
    }
   ],
   "source": [
    "# After determining the best hyperparameter 'C' from cross-validation:\n",
    "best_C = best_hyperparams  # This is the best 'C' found during cross-validation\n",
    "\n",
    "# Normalize the entire development set and the test set\n",
    "scaler = StandardScaler()\n",
    "X_dev_scaled = scaler.fit_transform(X_dev)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Prepare development and test data\n",
    "train_data = pd.DataFrame(X_dev_scaled, columns=X.columns)\n",
    "train_data['time'] = time_dev.values\n",
    "train_data['event'] = y_dev.values\n",
    "test_data = pd.DataFrame(X_test_scaled, columns=X.columns)\n",
    "test_data['time'] = time_test.values\n",
    "test_data['event'] = y_test.values\n",
    "\n",
    "# fit logistic regression model \n",
    "log_reg = LogisticRegression(max_iter=1000, random_state=42, C=C, penalty='l2')\n",
    "log_reg.fit(X_dev_scaled, y_dev)\n",
    "\n",
    "# evaluate on val \n",
    "y_test_pred = log_reg.predict(X_test_scaled)\n",
    "y_test_prob = log_reg.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Calculate ROC curve and Youden's index for the test set\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_test_prob)\n",
    "\n",
    "# Calculate classification metrics on the test set\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "precision_test = precision_score(y_test, y_test_pred)\n",
    "recall_test = recall_score(y_test, y_test_pred)\n",
    "f1_test = f1_score(y_test, y_test_pred)\n",
    "auroc_test = roc_auc_score(y_test, y_test_prob)\n",
    "auprc_test = average_precision_score(y_test, y_test_prob)\n",
    "\n",
    "# Print the test set performance\n",
    "print(f\"Accuracy on test set: {accuracy_test:.4f}\")\n",
    "print(f\"Precision on test set: {precision_test:.4f}\")\n",
    "print(f\"Recall on test set: {recall_test:.4f}\")\n",
    "print(f\"F1-Score on test set: {f1_test:.4f}\")\n",
    "print(f\"AUROC on test set: {auroc_test:.4f}\")\n",
    "print(f\"AUPRC on test set: {auprc_test:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2424813",
   "metadata": {},
   "source": [
    "# Cox model with ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "09049054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regularization strength: 0\n",
      "Regularization strength: 1e-05\n",
      "Regularization strength: 0.0001\n",
      "Regularization strength: 0.001\n",
      "Regularization strength: 0.01\n",
      "Regularization strength: 0.1\n",
      "Regularization strength: 0.5\n",
      "Regularization strength: 1\n",
      "Regularization strength: 10\n",
      "Regularization strength: 100\n",
      "Regularization strength: 1000\n",
      "Regularization strength: 10000\n",
      "Best AUROC: 0.6864 (0.0178)\n",
      "Best hyperparameters: C = 1\n",
      "Accuracy: Mean = 0.6653 (0.0254)\n",
      "Precision: Mean = 0.6793 (0.0556)\n",
      "Recall: Mean = 0.6721 (0.1353)\n",
      "F1-Score: Mean = 0.6625 (0.0594)\n",
      "AUROC: Mean = 0.6864 (0.0178)\n",
      "AUPRC: Mean = 0.6855 (0.0258)\n"
     ]
    }
   ],
   "source": [
    "C_values = [0, 0.00001, 0.0001, 0.001, 0.01, 0.1, 0.5, 1, 10, 100, 1000, 10000]\n",
    "\n",
    "# Track the best results\n",
    "best_auroc_mean = 0\n",
    "best_auroc_std = 0\n",
    "best_metrics = None\n",
    "best_hyperparams = None\n",
    "\n",
    "# Perform grid search over C values\n",
    "for C in C_values:\n",
    "    print(f\"Regularization strength: {C}\")\n",
    "    \n",
    "    # Initialize lists to store the metrics for each fold\n",
    "    accuracy_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    f1_scores = []\n",
    "    auroc_scores = []\n",
    "    auprc_scores = []\n",
    "    concordance_indices = []\n",
    "\n",
    "    # Perform 5-fold cross-validation\n",
    "    for train_index, val_index in kf.split(X_dev, y_dev):\n",
    "        # Get train and validation data\n",
    "        X_train_fold, X_val_fold = X_dev.iloc[train_index], X_dev.iloc[val_index]\n",
    "        y_train_fold, y_val_fold = y_dev.iloc[train_index], y_dev.iloc[val_index]\n",
    "        time_train_fold, time_val_fold = time_dev.iloc[train_index], time_dev.iloc[val_index]\n",
    "\n",
    "        # Normalize the training set and apply the same params to val\n",
    "        scaler = StandardScaler()\n",
    "        X_train_fold_scaled = scaler.fit_transform(X_train_fold)\n",
    "        X_val_fold_scaled = scaler.transform(X_val_fold)\n",
    "\n",
    "        # Prepare train and validation data\n",
    "        train_data = pd.DataFrame(X_train_fold_scaled, columns=X.columns)\n",
    "        train_data['time'] = time_train_fold.values\n",
    "        train_data['event'] = y_train_fold.values\n",
    "        val_data = pd.DataFrame(X_val_fold_scaled, columns=X.columns)\n",
    "        val_data['time'] = time_val_fold.values\n",
    "        val_data['event'] = y_val_fold.values\n",
    "\n",
    "        # Fit Cox Proportional Hazards model\n",
    "        cox_model = CoxPHFitter(penalizer=C, l1_ratio=0)  # Regularization using penalizer\n",
    "        cox_model.fit(train_data, duration_col='time', event_col='event')\n",
    "\n",
    "        # Predict the partial hazard for the validation set\n",
    "        val_hazards = cox_model.predict_partial_hazard(val_data)\n",
    "\n",
    "        # Evaluate using concordance index\n",
    "        concordance_index_val = concordance_index(val_data['time'], -val_hazards, event_observed=val_data['event'])\n",
    "        concordance_indices.append(concordance_index_val)\n",
    "\n",
    "        # Calculate ROC curve and thresholds\n",
    "        fpr, tpr, thresholds = roc_curve(y_val_fold, val_hazards)\n",
    "\n",
    "        # Calculate the Youden index (TPR - FPR)\n",
    "        youden_index = tpr - fpr\n",
    "\n",
    "        # Find the index of the maximum Youden index\n",
    "        optimal_threshold_index = np.argmax(youden_index)\n",
    "\n",
    "        # Get the optimal threshold\n",
    "        optimal_threshold = thresholds[optimal_threshold_index]\n",
    "\n",
    "        # Classify the patients based on the optimal threshold\n",
    "        y_val_pred = (val_hazards >= optimal_threshold).astype(int)\n",
    "\n",
    "        # Calculate and store classification metrics\n",
    "        accuracy_scores.append(accuracy_score(y_val_fold, y_val_pred))\n",
    "        precision_scores.append(precision_score(y_val_fold, y_val_pred))\n",
    "        recall_scores.append(recall_score(y_val_fold, y_val_pred))\n",
    "        f1_scores.append(f1_score(y_val_fold, y_val_pred))\n",
    "        auroc_scores.append(roc_auc_score(y_val_fold, val_hazards))\n",
    "        auprc_scores.append(average_precision_score(y_val_fold, val_hazards))\n",
    "\n",
    "    # Calculate mean and standard deviation of AUROC\n",
    "    auroc_mean = np.mean(auroc_scores)\n",
    "    auroc_std = np.std(auroc_scores)\n",
    "\n",
    "    # Check if this is the best AUROC so far\n",
    "    if auroc_mean > best_auroc_mean:\n",
    "        best_auroc_mean = auroc_mean\n",
    "        best_auroc_std = auroc_std\n",
    "        best_metrics = {\n",
    "            'accuracy': (np.mean(accuracy_scores), np.std(accuracy_scores)),\n",
    "            'precision': (np.mean(precision_scores), np.std(precision_scores)),\n",
    "            'recall': (np.mean(recall_scores), np.std(recall_scores)),\n",
    "            'f1_score': (np.mean(f1_scores), np.std(f1_scores)),\n",
    "            'auroc': (auroc_mean, auroc_std),\n",
    "            'auprc': (np.mean(auprc_scores), np.std(auprc_scores))\n",
    "        }\n",
    "        best_hyperparams = C\n",
    "\n",
    "# Print the best results\n",
    "print(f\"Best AUROC: {best_metrics['auroc'][0]:.4f} ({best_metrics['auroc'][1]:.4f})\")\n",
    "print(f\"Best hyperparameters: C = {best_hyperparams}\")\n",
    "print(f\"Accuracy: Mean = {best_metrics['accuracy'][0]:.4f} ({best_metrics['accuracy'][1]:.4f})\")\n",
    "print(f\"Precision: Mean = {best_metrics['precision'][0]:.4f} ({best_metrics['precision'][1]:.4f})\")\n",
    "print(f\"Recall: Mean = {best_metrics['recall'][0]:.4f} ({best_metrics['recall'][1]:.4f})\")\n",
    "print(f\"F1-Score: Mean = {best_metrics['f1_score'][0]:.4f} ({best_metrics['f1_score'][1]:.4f})\")\n",
    "print(f\"AUROC: Mean = {best_metrics['auroc'][0]:.4f} ({best_metrics['auroc'][1]:.4f})\")\n",
    "print(f\"AUPRC: Mean = {best_metrics['auprc'][0]:.4f} ({best_metrics['auprc'][1]:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a2a91c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concordance Index on test set: 0.7244\n",
      "Accuracy on test set: 0.7500\n",
      "Precision on test set: 0.7674\n",
      "Recall on test set: 0.7253\n",
      "F1-Score on test set: 0.7458\n",
      "AUROC on test set: 0.7921\n",
      "AUPRC on test set: 0.7714\n"
     ]
    }
   ],
   "source": [
    "# After determining the best hyperparameter 'C' from cross-validation:\n",
    "best_C = best_hyperparams  # This is the best 'C' found during cross-validation\n",
    "\n",
    "# Normalize the entire development set and the test set\n",
    "scaler = StandardScaler()\n",
    "X_dev_scaled = scaler.fit_transform(X_dev)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Prepare development and test data\n",
    "train_data = pd.DataFrame(X_dev_scaled, columns=X.columns)\n",
    "train_data['time'] = time_dev.values\n",
    "train_data['event'] = y_dev.values\n",
    "test_data = pd.DataFrame(X_test_scaled, columns=X.columns)\n",
    "test_data['time'] = time_test.values\n",
    "test_data['event'] = y_test.values\n",
    "\n",
    "# Fit the Cox model using the best regularization parameter found on the entire development set\n",
    "cox_model = CoxPHFitter(penalizer=best_C, l1_ratio=0)\n",
    "cox_model.fit(train_data, duration_col='time', event_col='event')\n",
    "\n",
    "# Predict the partial hazard for the test set\n",
    "test_hazards = cox_model.predict_partial_hazard(test_data)\n",
    "\n",
    "# Evaluate using the concordance index on the test set\n",
    "concordance_index_test = concordance_index(test_data['time'], -test_hazards, event_observed=test_data['event'])\n",
    "print(f\"Concordance Index on test set: {concordance_index_test:.4f}\")\n",
    "\n",
    "# Calculate ROC curve and Youden's index for the test set\n",
    "fpr, tpr, thresholds = roc_curve(y_test, test_hazards)\n",
    "\n",
    "# Calculate the Youden index (TPR - FPR)\n",
    "youden_index = tpr - fpr\n",
    "\n",
    "# Find the index of the maximum Youden index\n",
    "optimal_threshold_index = np.argmax(youden_index)\n",
    "\n",
    "# Get the optimal threshold for binary classification\n",
    "optimal_threshold = thresholds[optimal_threshold_index]\n",
    "\n",
    "# Classify the patients based on the optimal threshold\n",
    "y_test_pred = (test_hazards >= optimal_threshold).astype(int)\n",
    "\n",
    "# Calculate classification metrics on the test set\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "precision_test = precision_score(y_test, y_test_pred)\n",
    "recall_test = recall_score(y_test, y_test_pred)\n",
    "f1_test = f1_score(y_test, y_test_pred)\n",
    "auroc_test = roc_auc_score(y_test, test_hazards)\n",
    "auprc_test = average_precision_score(y_test, test_hazards)\n",
    "\n",
    "# Print the test set performance\n",
    "print(f\"Accuracy on test set: {accuracy_test:.4f}\")\n",
    "print(f\"Precision on test set: {precision_test:.4f}\")\n",
    "print(f\"Recall on test set: {recall_test:.4f}\")\n",
    "print(f\"F1-Score on test set: {f1_test:.4f}\")\n",
    "print(f\"AUROC on test set: {auroc_test:.4f}\")\n",
    "print(f\"AUPRC on test set: {auprc_test:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ba1bf6",
   "metadata": {},
   "source": [
    "# Cox model with LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f50b7928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regularization strength: 0\n",
      "Regularization strength: 1e-05\n",
      "Regularization strength: 0.0001\n",
      "Regularization strength: 0.001\n",
      "Regularization strength: 0.01\n",
      "Regularization strength: 0.1\n",
      "Regularization strength: 0.5\n",
      "Regularization strength: 1\n",
      "Regularization strength: 10\n",
      "Regularization strength: 100\n",
      "Regularization strength: 1000\n",
      "Regularization strength: 10000\n",
      "Best AUROC: 0.6855 (0.0205)\n",
      "Best hyperparameters: C = 1\n",
      "Accuracy: Mean = 0.6597 (0.0191)\n",
      "Precision: Mean = 0.7237 (0.0747)\n",
      "Recall: Mean = 0.5760 (0.1788)\n",
      "F1-Score: Mean = 0.6151 (0.0888)\n",
      "AUROC: Mean = 0.6855 (0.0205)\n",
      "AUPRC: Mean = 0.6883 (0.0270)\n"
     ]
    }
   ],
   "source": [
    "C_values = [0, 0.00001, 0.0001, 0.001, 0.01, 0.1, 0.5, 1, 10, 100, 1000, 10000]\n",
    "\n",
    "# Track the best results\n",
    "best_auroc_mean = 0\n",
    "best_auroc_std = 0\n",
    "best_metrics = None\n",
    "best_hyperparams = None\n",
    "\n",
    "# Perform grid search over C values\n",
    "for C in C_values:\n",
    "    print(f\"Regularization strength: {C}\")\n",
    "    \n",
    "    # Initialize lists to store the metrics for each fold\n",
    "    accuracy_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    f1_scores = []\n",
    "    auroc_scores = []\n",
    "    auprc_scores = []\n",
    "    concordance_indices = []\n",
    "\n",
    "    # Perform 5-fold cross-validation\n",
    "    for train_index, val_index in kf.split(X_dev, y_dev):\n",
    "        # Get train and validation data\n",
    "        X_train_fold, X_val_fold = X_dev.iloc[train_index], X_dev.iloc[val_index]\n",
    "        y_train_fold, y_val_fold = y_dev.iloc[train_index], y_dev.iloc[val_index]\n",
    "        time_train_fold, time_val_fold = time_dev.iloc[train_index], time_dev.iloc[val_index]\n",
    "\n",
    "        # Normalize the training set and apply the same params to val\n",
    "        scaler = StandardScaler()\n",
    "        X_train_fold_scaled = scaler.fit_transform(X_train_fold)\n",
    "        X_val_fold_scaled = scaler.transform(X_val_fold)\n",
    "\n",
    "        # Prepare train and validation data\n",
    "        train_data = pd.DataFrame(X_train_fold_scaled, columns=X.columns)\n",
    "        train_data['time'] = time_train_fold.values\n",
    "        train_data['event'] = y_train_fold.values\n",
    "        val_data = pd.DataFrame(X_val_fold_scaled, columns=X.columns)\n",
    "        val_data['time'] = time_val_fold.values\n",
    "        val_data['event'] = y_val_fold.values\n",
    "\n",
    "        # Fit Cox Proportional Hazards model\n",
    "        cox_model = CoxPHFitter(penalizer=C, l1_ratio=1)  # Regularization using penalizer\n",
    "        cox_model.fit(train_data, duration_col='time', event_col='event')\n",
    "\n",
    "        # Predict the partial hazard for the validation set\n",
    "        val_hazards = cox_model.predict_partial_hazard(val_data)\n",
    "\n",
    "        # Evaluate using concordance index\n",
    "        concordance_index_val = concordance_index(val_data['time'], -val_hazards, event_observed=val_data['event'])\n",
    "        concordance_indices.append(concordance_index_val)\n",
    "\n",
    "        # Calculate ROC curve and thresholds\n",
    "        fpr, tpr, thresholds = roc_curve(y_val_fold, val_hazards)\n",
    "\n",
    "        # Calculate the Youden index (TPR - FPR)\n",
    "        youden_index = tpr - fpr\n",
    "\n",
    "        # Find the index of the maximum Youden index\n",
    "        optimal_threshold_index = np.argmax(youden_index)\n",
    "\n",
    "        # Get the optimal threshold\n",
    "        optimal_threshold = thresholds[optimal_threshold_index]\n",
    "\n",
    "        # Classify the patients based on the optimal threshold\n",
    "        y_val_pred = (val_hazards >= optimal_threshold).astype(int)\n",
    "\n",
    "        # Calculate and store classification metrics\n",
    "        accuracy_scores.append(accuracy_score(y_val_fold, y_val_pred))\n",
    "        precision_scores.append(precision_score(y_val_fold, y_val_pred))\n",
    "        recall_scores.append(recall_score(y_val_fold, y_val_pred))\n",
    "        f1_scores.append(f1_score(y_val_fold, y_val_pred))\n",
    "        auroc_scores.append(roc_auc_score(y_val_fold, val_hazards))\n",
    "        auprc_scores.append(average_precision_score(y_val_fold, val_hazards))\n",
    "\n",
    "    # Calculate mean and standard deviation of AUROC\n",
    "    auroc_mean = np.mean(auroc_scores)\n",
    "    auroc_std = np.std(auroc_scores)\n",
    "\n",
    "    # Check if this is the best AUROC so far\n",
    "    if auroc_mean > best_auroc_mean:\n",
    "        best_auroc_mean = auroc_mean\n",
    "        best_auroc_std = auroc_std\n",
    "        best_metrics = {\n",
    "            'accuracy': (np.mean(accuracy_scores), np.std(accuracy_scores)),\n",
    "            'precision': (np.mean(precision_scores), np.std(precision_scores)),\n",
    "            'recall': (np.mean(recall_scores), np.std(recall_scores)),\n",
    "            'f1_score': (np.mean(f1_scores), np.std(f1_scores)),\n",
    "            'auroc': (auroc_mean, auroc_std),\n",
    "            'auprc': (np.mean(auprc_scores), np.std(auprc_scores))\n",
    "        }\n",
    "        best_hyperparams = C\n",
    "\n",
    "# Print the best results\n",
    "print(f\"Best AUROC: {best_metrics['auroc'][0]:.4f} ({best_metrics['auroc'][1]:.4f})\")\n",
    "print(f\"Best hyperparameters: C = {best_hyperparams}\")\n",
    "print(f\"Accuracy: Mean = {best_metrics['accuracy'][0]:.4f} ({best_metrics['accuracy'][1]:.4f})\")\n",
    "print(f\"Precision: Mean = {best_metrics['precision'][0]:.4f} ({best_metrics['precision'][1]:.4f})\")\n",
    "print(f\"Recall: Mean = {best_metrics['recall'][0]:.4f} ({best_metrics['recall'][1]:.4f})\")\n",
    "print(f\"F1-Score: Mean = {best_metrics['f1_score'][0]:.4f} ({best_metrics['f1_score'][1]:.4f})\")\n",
    "print(f\"AUROC: Mean = {best_metrics['auroc'][0]:.4f} ({best_metrics['auroc'][1]:.4f})\")\n",
    "print(f\"AUPRC: Mean = {best_metrics['auprc'][0]:.4f} ({best_metrics['auprc'][1]:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1249d5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concordance Index on test set: 0.7218\n",
      "Accuracy on test set: 0.7556\n",
      "Precision on test set: 0.7423\n",
      "Recall on test set: 0.7912\n",
      "F1-Score on test set: 0.7660\n",
      "AUROC on test set: 0.7906\n",
      "AUPRC on test set: 0.7700\n"
     ]
    }
   ],
   "source": [
    "# After determining the best hyperparameter 'C' from cross-validation:\n",
    "best_C = best_hyperparams  # This is the best 'C' found during cross-validation\n",
    "\n",
    "# Normalize the entire development set and the test set\n",
    "scaler = StandardScaler()\n",
    "X_dev_scaled = scaler.fit_transform(X_dev)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Prepare development and test data\n",
    "train_data = pd.DataFrame(X_dev_scaled, columns=X.columns)\n",
    "train_data['time'] = time_dev.values\n",
    "train_data['event'] = y_dev.values\n",
    "test_data = pd.DataFrame(X_test_scaled, columns=X.columns)\n",
    "test_data['time'] = time_test.values\n",
    "test_data['event'] = y_test.values\n",
    "\n",
    "# Fit the Cox model using the best regularization parameter found on the entire development set\n",
    "cox_model = CoxPHFitter(penalizer=best_C, l1_ratio=1)\n",
    "cox_model.fit(train_data, duration_col='time', event_col='event')\n",
    "\n",
    "# Predict the partial hazard for the test set\n",
    "test_hazards = cox_model.predict_partial_hazard(test_data)\n",
    "\n",
    "# Evaluate using the concordance index on the test set\n",
    "concordance_index_test = concordance_index(test_data['time'], -test_hazards, event_observed=test_data['event'])\n",
    "print(f\"Concordance Index on test set: {concordance_index_test:.4f}\")\n",
    "\n",
    "# Calculate ROC curve and Youden's index for the test set\n",
    "fpr, tpr, thresholds = roc_curve(y_test, test_hazards)\n",
    "\n",
    "# Calculate the Youden index (TPR - FPR)\n",
    "youden_index = tpr - fpr\n",
    "\n",
    "# Find the index of the maximum Youden index\n",
    "optimal_threshold_index = np.argmax(youden_index)\n",
    "\n",
    "# Get the optimal threshold for binary classification\n",
    "optimal_threshold = thresholds[optimal_threshold_index]\n",
    "\n",
    "# Classify the patients based on the optimal threshold\n",
    "y_test_pred = (test_hazards >= optimal_threshold).astype(int)\n",
    "\n",
    "# Calculate classification metrics on the test set\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "precision_test = precision_score(y_test, y_test_pred)\n",
    "recall_test = recall_score(y_test, y_test_pred)\n",
    "f1_test = f1_score(y_test, y_test_pred)\n",
    "auroc_test = roc_auc_score(y_test, test_hazards)\n",
    "auprc_test = average_precision_score(y_test, test_hazards)\n",
    "\n",
    "# Print the test set performance\n",
    "print(f\"Accuracy on test set: {accuracy_test:.4f}\")\n",
    "print(f\"Precision on test set: {precision_test:.4f}\")\n",
    "print(f\"Recall on test set: {recall_test:.4f}\")\n",
    "print(f\"F1-Score on test set: {f1_test:.4f}\")\n",
    "print(f\"AUROC on test set: {auroc_test:.4f}\")\n",
    "print(f\"AUPRC on test set: {auprc_test:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf99e59",
   "metadata": {},
   "source": [
    "# RBF SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6883cafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regularization strength (C): 0.01, Gamma: scale\n",
      "Regularization strength (C): 0.01, Gamma: auto\n",
      "Regularization strength (C): 0.1, Gamma: scale\n",
      "Regularization strength (C): 0.1, Gamma: auto\n",
      "Regularization strength (C): 1, Gamma: scale\n",
      "Regularization strength (C): 1, Gamma: auto\n",
      "Regularization strength (C): 10, Gamma: scale\n",
      "Regularization strength (C): 10, Gamma: auto\n",
      "Regularization strength (C): 100, Gamma: scale\n",
      "Regularization strength (C): 100, Gamma: auto\n",
      "Best AUROC: 0.7145 (0.0401)\n",
      "Best hyperparameters: C = 1, Gamma = scale\n",
      "Accuracy: Mean = 0.6458 (0.0520)\n",
      "Precision: Mean = 0.6533 (0.0490)\n",
      "Recall: Mean = 0.6308 (0.0636)\n",
      "F1-Score: Mean = 0.6417 (0.0558)\n",
      "AUROC: Mean = 0.7145 (0.0401)\n",
      "AUPRC: Mean = 0.7098 (0.0263)\n"
     ]
    }
   ],
   "source": [
    "# Initialize StratifiedKFold for cross-validation\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define hyperparameters to tune (C and gamma for RBF kernel)\n",
    "C_values = [0.01, 0.1, 1, 10, 100]\n",
    "gammas = ['scale', 'auto']  # Gamma options for the RBF kernel\n",
    "\n",
    "# Track the best results\n",
    "best_auroc_mean = 0\n",
    "best_auroc_std = 0\n",
    "best_metrics = None\n",
    "best_hyperparams = None\n",
    "\n",
    "# Perform grid search over C and gamma\n",
    "for C in C_values:\n",
    "    for gamma in gammas:\n",
    "        print(f\"Regularization strength (C): {C}, Gamma: {gamma}\")\n",
    "        \n",
    "        # Initialize lists to store metrics for each fold\n",
    "        accuracy_scores = []\n",
    "        precision_scores = []\n",
    "        recall_scores = []\n",
    "        f1_scores = []\n",
    "        auroc_scores = []\n",
    "        auprc_scores = []\n",
    "\n",
    "        # Perform 5-fold cross-validation\n",
    "        for train_index, val_index in kf.split(X_dev, y_dev):\n",
    "            # Get train and validation data\n",
    "            X_train_fold, X_val_fold = X_dev.iloc[train_index], X_dev.iloc[val_index]\n",
    "            y_train_fold, y_val_fold = y_dev.iloc[train_index], y_dev.iloc[val_index]\n",
    "\n",
    "            # Normalize the training set and apply the same params to validation set\n",
    "            scaler = StandardScaler()\n",
    "            X_train_fold_scaled = scaler.fit_transform(X_train_fold)\n",
    "            X_val_fold_scaled = scaler.transform(X_val_fold)\n",
    "\n",
    "            # Fit SVM model with RBF kernel\n",
    "            svm_model = SVC(C=C, kernel='rbf', gamma=gamma, probability=True, random_state=42)\n",
    "            svm_model.fit(X_train_fold_scaled, y_train_fold)\n",
    "\n",
    "            # Predict on validation set\n",
    "            y_val_pred = svm_model.predict(X_val_fold_scaled)\n",
    "            y_val_prob = svm_model.predict_proba(X_val_fold_scaled)[:, 1]  # Probabilities for positive class\n",
    "\n",
    "            # Record validation metrics\n",
    "            accuracy_scores.append(accuracy_score(y_val_fold, y_val_pred))\n",
    "            precision_scores.append(precision_score(y_val_fold, y_val_pred))\n",
    "            recall_scores.append(recall_score(y_val_fold, y_val_pred))\n",
    "            f1_scores.append(f1_score(y_val_fold, y_val_pred))\n",
    "            auroc_scores.append(roc_auc_score(y_val_fold, y_val_prob))\n",
    "            auprc_scores.append(average_precision_score(y_val_fold, y_val_prob))\n",
    "\n",
    "        # Calculate mean and standard deviation of AUROC\n",
    "        auroc_mean = np.mean(auroc_scores)\n",
    "        auroc_std = np.std(auroc_scores)\n",
    "\n",
    "        # Check if this is the best AUROC so far\n",
    "        if auroc_mean > best_auroc_mean:\n",
    "            best_auroc_mean = auroc_mean\n",
    "            best_auroc_std = auroc_std\n",
    "            best_metrics = {\n",
    "                'accuracy': (np.mean(accuracy_scores), np.std(accuracy_scores)),\n",
    "                'precision': (np.mean(precision_scores), np.std(precision_scores)),\n",
    "                'recall': (np.mean(recall_scores), np.std(recall_scores)),\n",
    "                'f1_score': (np.mean(f1_scores), np.std(f1_scores)),\n",
    "                'auroc': (auroc_mean, auroc_std),\n",
    "                'auprc': (np.mean(auprc_scores), np.std(auprc_scores))\n",
    "            }\n",
    "            best_hyperparams = {'C': C, 'gamma': gamma}\n",
    "\n",
    "        # Report mean and standard deviation of cross-validation metrics\n",
    "        # print(f\"\\tAccuracy: Mean = {np.mean(accuracy_scores):.4f}, Std = {np.std(accuracy_scores):.4f}\")\n",
    "        # print(f\"\\tPrecision: Mean = {np.mean(precision_scores):.4f}, Std = {np.std(precision_scores):.4f}\")\n",
    "        # print(f\"\\tRecall: Mean = {np.mean(recall_scores):.4f}, Std = {np.std(recall_scores):.4f}\")\n",
    "        # print(f\"\\tF1-Score: Mean = {np.mean(f1_scores):.4f}, Std = {np.std(f1_scores):.4f}\")\n",
    "        # print(f\"\\tAUROC: Mean = {auroc_mean:.4f}, Std = {auroc_std:.4f}\")\n",
    "        # print(f\"\\tAUPRC: Mean = {np.mean(auprc_scores):.4f}, Std = {np.std(auprc_scores):.4f}\")\n",
    "\n",
    "# Print the best results\n",
    "print(f\"Best AUROC: {best_metrics['auroc'][0]:.4f} ({best_metrics['auroc'][1]:.4f})\")\n",
    "print(f\"Best hyperparameters: C = {best_hyperparams['C']}, Gamma = {best_hyperparams['gamma']}\")\n",
    "print(f\"Accuracy: Mean = {best_metrics['accuracy'][0]:.4f} ({best_metrics['accuracy'][1]:.4f})\")\n",
    "print(f\"Precision: Mean = {best_metrics['precision'][0]:.4f} ({best_metrics['precision'][1]:.4f})\")\n",
    "print(f\"Recall: Mean = {best_metrics['recall'][0]:.4f} ({best_metrics['recall'][1]:.4f})\")\n",
    "print(f\"F1-Score: Mean = {best_metrics['f1_score'][0]:.4f} ({best_metrics['f1_score'][1]:.4f})\")\n",
    "print(f\"AUROC: Mean = {best_metrics['auroc'][0]:.4f} ({best_metrics['auroc'][1]:.4f})\")\n",
    "print(f\"AUPRC: Mean = {best_metrics['auprc'][0]:.4f} ({best_metrics['auprc'][1]:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0bd63ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.7222\n",
      "Precision on test set: 0.7412\n",
      "Recall on test set: 0.6923\n",
      "F1-Score on test set: 0.7159\n",
      "AUROC on test set: 0.7329\n",
      "AUPRC on test set: 0.7232\n"
     ]
    }
   ],
   "source": [
    "# After determining the best hyperparameters 'C' and 'gamma' from cross-validation:\n",
    "best_C = best_hyperparams['C']\n",
    "best_gamma = best_hyperparams['gamma']\n",
    "\n",
    "# Normalize the entire development set and the test set\n",
    "scaler = StandardScaler()\n",
    "X_dev_scaled = scaler.fit_transform(X_dev)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Fit the SVM model on the entire development set using the best hyperparameters\n",
    "svm_model = SVC(C=best_C, kernel='rbf', gamma=best_gamma, probability=True, random_state=42)\n",
    "svm_model.fit(X_dev_scaled, y_dev)\n",
    "\n",
    "# Predict on the test set\n",
    "y_test_pred = svm_model.predict(X_test_scaled)\n",
    "y_test_prob = svm_model.predict_proba(X_test_scaled)[:, 1]  # Probabilities for the positive class\n",
    "\n",
    "# Evaluate the test set metrics\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "precision_test = precision_score(y_test, y_test_pred)\n",
    "recall_test = recall_score(y_test, y_test_pred)\n",
    "f1_test = f1_score(y_test, y_test_pred)\n",
    "auroc_test = roc_auc_score(y_test, y_test_prob)\n",
    "auprc_test = average_precision_score(y_test, y_test_prob)\n",
    "\n",
    "# Print the test set performance\n",
    "print(f\"Accuracy on test set: {accuracy_test:.4f}\")\n",
    "print(f\"Precision on test set: {precision_test:.4f}\")\n",
    "print(f\"Recall on test set: {recall_test:.4f}\")\n",
    "print(f\"F1-Score on test set: {f1_test:.4f}\")\n",
    "print(f\"AUROC on test set: {auroc_test:.4f}\")\n",
    "print(f\"AUPRC on test set: {auprc_test:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe85eea",
   "metadata": {},
   "source": [
    "# Poly SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2c6b138a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, average_precision_score, roc_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c80973a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regularization strength (C): 0.01, Gamma: scale, Degree: 2\n",
      "Regularization strength (C): 0.01, Gamma: scale, Degree: 3\n",
      "Regularization strength (C): 0.01, Gamma: scale, Degree: 4\n",
      "Regularization strength (C): 0.01, Gamma: auto, Degree: 2\n",
      "Regularization strength (C): 0.01, Gamma: auto, Degree: 3\n",
      "Regularization strength (C): 0.01, Gamma: auto, Degree: 4\n",
      "Regularization strength (C): 0.1, Gamma: scale, Degree: 2\n",
      "Regularization strength (C): 0.1, Gamma: scale, Degree: 3\n",
      "Regularization strength (C): 0.1, Gamma: scale, Degree: 4\n",
      "Regularization strength (C): 0.1, Gamma: auto, Degree: 2\n",
      "Regularization strength (C): 0.1, Gamma: auto, Degree: 3\n",
      "Regularization strength (C): 0.1, Gamma: auto, Degree: 4\n",
      "Regularization strength (C): 1, Gamma: scale, Degree: 2\n",
      "Regularization strength (C): 1, Gamma: scale, Degree: 3\n",
      "Regularization strength (C): 1, Gamma: scale, Degree: 4\n",
      "Regularization strength (C): 1, Gamma: auto, Degree: 2\n",
      "Regularization strength (C): 1, Gamma: auto, Degree: 3\n",
      "Regularization strength (C): 1, Gamma: auto, Degree: 4\n",
      "Regularization strength (C): 10, Gamma: scale, Degree: 2\n",
      "Regularization strength (C): 10, Gamma: scale, Degree: 3\n",
      "Regularization strength (C): 10, Gamma: scale, Degree: 4\n",
      "Regularization strength (C): 10, Gamma: auto, Degree: 2\n",
      "Regularization strength (C): 10, Gamma: auto, Degree: 3\n",
      "Regularization strength (C): 10, Gamma: auto, Degree: 4\n",
      "Regularization strength (C): 100, Gamma: scale, Degree: 2\n",
      "Regularization strength (C): 100, Gamma: scale, Degree: 3\n",
      "Regularization strength (C): 100, Gamma: scale, Degree: 4\n",
      "Regularization strength (C): 100, Gamma: auto, Degree: 2\n",
      "Regularization strength (C): 100, Gamma: auto, Degree: 3\n",
      "Regularization strength (C): 100, Gamma: auto, Degree: 4\n",
      "Best AUROC: 0.6998 (0.0323)\n",
      "Best hyperparameters: C = 0.1, Gamma = scale, Degree = 2\n",
      "Accuracy: Mean = 0.6486 (0.0462)\n",
      "Precision: Mean = 0.6532 (0.0454)\n",
      "Recall: Mean = 0.6473 (0.0626)\n",
      "F1-Score: Mean = 0.6493 (0.0494)\n",
      "AUROC: Mean = 0.6998 (0.0323)\n",
      "AUPRC: Mean = 0.6910 (0.0308)\n"
     ]
    }
   ],
   "source": [
    "# Initialize StratifiedKFold for cross-validation\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define hyperparameters to tune for the Polynomial kernel\n",
    "C_values = [0.01, 0.1, 1, 10, 100]\n",
    "gammas = ['scale', 'auto']  # Gamma options for the polynomial kernel\n",
    "degrees = [2, 3, 4]  # Polynomial degrees to explore\n",
    "\n",
    "# Track the best results\n",
    "best_auroc_mean = 0\n",
    "best_auroc_std = 0\n",
    "best_metrics = None\n",
    "best_hyperparams = None\n",
    "\n",
    "# Perform grid search over C, gamma, and degree\n",
    "for C in C_values:\n",
    "    for gamma in gammas:\n",
    "        for degree in degrees:\n",
    "            print(f\"Regularization strength (C): {C}, Gamma: {gamma}, Degree: {degree}\")\n",
    "            \n",
    "            # Initialize lists to store metrics for each fold\n",
    "            accuracy_scores = []\n",
    "            precision_scores = []\n",
    "            recall_scores = []\n",
    "            f1_scores = []\n",
    "            auroc_scores = []\n",
    "            auprc_scores = []\n",
    "\n",
    "            # Perform 5-fold cross-validation\n",
    "            for train_index, val_index in kf.split(X_dev, y_dev):\n",
    "                # Get train and validation data\n",
    "                X_train_fold, X_val_fold = X_dev.iloc[train_index], X_dev.iloc[val_index]\n",
    "                y_train_fold, y_val_fold = y_dev.iloc[train_index], y_dev.iloc[val_index]\n",
    "\n",
    "                # Normalize the training set and apply the same parameters to validation\n",
    "                scaler = StandardScaler()\n",
    "                X_train_fold_scaled = scaler.fit_transform(X_train_fold)\n",
    "                X_val_fold_scaled = scaler.transform(X_val_fold)\n",
    "\n",
    "                # Fit SVM model with Polynomial kernel\n",
    "                svm_model = SVC(C=C, kernel='poly', gamma=gamma, degree=degree, coef0=1, probability=True, random_state=42)\n",
    "                svm_model.fit(X_train_fold_scaled, y_train_fold)\n",
    "\n",
    "                # Predict on validation set\n",
    "                y_val_pred = svm_model.predict(X_val_fold_scaled)\n",
    "                y_val_prob = svm_model.predict_proba(X_val_fold_scaled)[:, 1]  # Probabilities for positive class\n",
    "\n",
    "                # Record validation metrics\n",
    "                accuracy_scores.append(accuracy_score(y_val_fold, y_val_pred))\n",
    "                precision_scores.append(precision_score(y_val_fold, y_val_pred))\n",
    "                recall_scores.append(recall_score(y_val_fold, y_val_pred))\n",
    "                f1_scores.append(f1_score(y_val_fold, y_val_pred))\n",
    "                auroc_scores.append(roc_auc_score(y_val_fold, y_val_prob))\n",
    "                auprc_scores.append(average_precision_score(y_val_fold, y_val_prob))\n",
    "\n",
    "            # Calculate mean and standard deviation of AUROC\n",
    "            auroc_mean = np.mean(auroc_scores)\n",
    "            auroc_std = np.std(auroc_scores)\n",
    "\n",
    "            # Check if this is the best AUROC so far\n",
    "            if auroc_mean > best_auroc_mean:\n",
    "                best_auroc_mean = auroc_mean\n",
    "                best_auroc_std = auroc_std\n",
    "                best_metrics = {\n",
    "                    'accuracy': (np.mean(accuracy_scores), np.std(accuracy_scores)),\n",
    "                    'precision': (np.mean(precision_scores), np.std(precision_scores)),\n",
    "                    'recall': (np.mean(recall_scores), np.std(recall_scores)),\n",
    "                    'f1_score': (np.mean(f1_scores), np.std(f1_scores)),\n",
    "                    'auroc': (auroc_mean, auroc_std),\n",
    "                    'auprc': (np.mean(auprc_scores), np.std(auprc_scores))\n",
    "                }\n",
    "                best_hyperparams = {'C': C, 'gamma': gamma, 'degree': degree}\n",
    "\n",
    "            # Report mean and standard deviation of cross-validation metrics\n",
    "            # print(f\"\\tAccuracy:  {np.mean(accuracy_scores):.4f} ({np.std(accuracy_scores):.4f})\")\n",
    "            # print(f\"\\tPrecision: {np.mean(precision_scores):.4f} ({np.std(precision_scores):.4f})\")\n",
    "            # print(f\"\\tRecall:    {np.mean(recall_scores):.4f} ({np.std(recall_scores):.4f})\")\n",
    "            # print(f\"\\tF1-Score:  {np.mean(f1_scores):.4f} ({np.std(f1_scores):.4f})\")\n",
    "            # print(f\"\\tAUROC:     {auroc_mean:.4f} ({auroc_std:.4f})\")\n",
    "            # print(f\"\\tAUPRC:     {np.mean(auprc_scores):.4f} ({np.std(auprc_scores):.4f})\")\n",
    "\n",
    "# Print the best results\n",
    "print(f\"Best AUROC: {best_metrics['auroc'][0]:.4f} ({best_metrics['auroc'][1]:.4f})\")\n",
    "print(f\"Best hyperparameters: C = {best_hyperparams['C']}, Gamma = {best_hyperparams['gamma']}, Degree = {best_hyperparams['degree']}\")\n",
    "print(f\"Accuracy: Mean = {best_metrics['accuracy'][0]:.4f} ({best_metrics['accuracy'][1]:.4f})\")\n",
    "print(f\"Precision: Mean = {best_metrics['precision'][0]:.4f} ({best_metrics['precision'][1]:.4f})\")\n",
    "print(f\"Recall: Mean = {best_metrics['recall'][0]:.4f} ({best_metrics['recall'][1]:.4f})\")\n",
    "print(f\"F1-Score: Mean = {best_metrics['f1_score'][0]:.4f} ({best_metrics['f1_score'][1]:.4f})\")\n",
    "print(f\"AUROC: Mean = {best_metrics['auroc'][0]:.4f} ({best_metrics['auroc'][1]:.4f})\")\n",
    "print(f\"AUPRC: Mean = {best_metrics['auprc'][0]:.4f} ({best_metrics['auprc'][1]:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6e09d69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.6944\n",
      "Precision on test set: 0.7143\n",
      "Recall on test set: 0.6593\n",
      "F1-Score on test set: 0.6857\n",
      "AUROC on test set: 0.7602\n",
      "AUPRC on test set: 0.7481\n"
     ]
    }
   ],
   "source": [
    "# After determining the best hyperparameters 'C', 'gamma', and 'degree' from cross-validation:\n",
    "best_C = best_hyperparams['C']\n",
    "best_gamma = best_hyperparams['gamma']\n",
    "best_degree = best_hyperparams['degree']\n",
    "\n",
    "# Normalize the entire development set and the test set\n",
    "scaler = StandardScaler()\n",
    "X_dev_scaled = scaler.fit_transform(X_dev)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Fit the SVM model on the entire development set using the best hyperparameters\n",
    "svm_model = SVC(C=best_C, kernel='poly', gamma=best_gamma, degree=best_degree, coef0=1, probability=True, random_state=42)\n",
    "svm_model.fit(X_dev_scaled, y_dev)\n",
    "\n",
    "# Predict on the test set\n",
    "y_test_pred = svm_model.predict(X_test_scaled)\n",
    "y_test_prob = svm_model.predict_proba(X_test_scaled)[:, 1]  # Probabilities for the positive class\n",
    "\n",
    "# Evaluate the test set metrics\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "precision_test = precision_score(y_test, y_test_pred)\n",
    "recall_test = recall_score(y_test, y_test_pred)\n",
    "f1_test = f1_score(y_test, y_test_pred)\n",
    "auroc_test = roc_auc_score(y_test, y_test_prob)\n",
    "auprc_test = average_precision_score(y_test, y_test_prob)\n",
    "\n",
    "# Print the test set performance\n",
    "print(f\"Accuracy on test set: {accuracy_test:.4f}\")\n",
    "print(f\"Precision on test set: {precision_test:.4f}\")\n",
    "print(f\"Recall on test set: {recall_test:.4f}\")\n",
    "print(f\"F1-Score on test set: {f1_test:.4f}\")\n",
    "print(f\"AUROC on test set: {auroc_test:.4f}\")\n",
    "print(f\"AUPRC on test set: {auprc_test:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19da8ad0",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "613bbd19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.0001, Learning Rate: constant, Max Iterations: 50\n",
      "\tAccuracy:  0.5917 (0.0296)\n",
      "\tPrecision: 0.5939 (0.0257)\n",
      "\tRecall:    0.5978 (0.0520)\n",
      "\tF1-Score:  0.5953 (0.0369)\n",
      "\tAUROC:     0.6163 (0.0314)\n",
      "\tAUPRC:     0.6263 (0.0260)\n",
      "Alpha: 0.0001, Learning Rate: constant, Max Iterations: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tAccuracy:  0.6222 (0.0336)\n",
      "\tPrecision: 0.6352 (0.0381)\n",
      "\tRecall:    0.5923 (0.0242)\n",
      "\tF1-Score:  0.6128 (0.0299)\n",
      "\tAUROC:     0.6550 (0.0221)\n",
      "\tAUPRC:     0.6548 (0.0221)\n",
      "Alpha: 0.0001, Learning Rate: constant, Max Iterations: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tAccuracy:  0.6431 (0.0293)\n",
      "\tPrecision: 0.6504 (0.0298)\n",
      "\tRecall:    0.6337 (0.0561)\n",
      "\tF1-Score:  0.6407 (0.0352)\n",
      "\tAUROC:     0.6741 (0.0145)\n",
      "\tAUPRC:     0.6693 (0.0206)\n",
      "Alpha: 0.0001, Learning Rate: constant, Max Iterations: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tAccuracy:  0.6458 (0.0407)\n",
      "\tPrecision: 0.6504 (0.0419)\n",
      "\tRecall:    0.6475 (0.0725)\n",
      "\tF1-Score:  0.6470 (0.0463)\n",
      "\tAUROC:     0.6833 (0.0255)\n",
      "\tAUPRC:     0.6735 (0.0235)\n",
      "Alpha: 0.0001, Learning Rate: adaptive, Max Iterations: 50\n",
      "\tAccuracy:  0.5917 (0.0296)\n",
      "\tPrecision: 0.5939 (0.0257)\n",
      "\tRecall:    0.5978 (0.0520)\n",
      "\tF1-Score:  0.5953 (0.0369)\n",
      "\tAUROC:     0.6163 (0.0314)\n",
      "\tAUPRC:     0.6263 (0.0260)\n",
      "Alpha: 0.0001, Learning Rate: adaptive, Max Iterations: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tAccuracy:  0.6222 (0.0336)\n",
      "\tPrecision: 0.6352 (0.0381)\n",
      "\tRecall:    0.5923 (0.0242)\n",
      "\tF1-Score:  0.6128 (0.0299)\n",
      "\tAUROC:     0.6550 (0.0221)\n",
      "\tAUPRC:     0.6548 (0.0221)\n",
      "Alpha: 0.0001, Learning Rate: adaptive, Max Iterations: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tAccuracy:  0.6431 (0.0293)\n",
      "\tPrecision: 0.6504 (0.0298)\n",
      "\tRecall:    0.6337 (0.0561)\n",
      "\tF1-Score:  0.6407 (0.0352)\n",
      "\tAUROC:     0.6741 (0.0145)\n",
      "\tAUPRC:     0.6693 (0.0206)\n",
      "Alpha: 0.0001, Learning Rate: adaptive, Max Iterations: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tAccuracy:  0.6458 (0.0407)\n",
      "\tPrecision: 0.6504 (0.0419)\n",
      "\tRecall:    0.6475 (0.0725)\n",
      "\tF1-Score:  0.6470 (0.0463)\n",
      "\tAUROC:     0.6833 (0.0255)\n",
      "\tAUPRC:     0.6735 (0.0235)\n",
      "Alpha: 0.001, Learning Rate: constant, Max Iterations: 50\n",
      "\tAccuracy:  0.5917 (0.0296)\n",
      "\tPrecision: 0.5939 (0.0257)\n",
      "\tRecall:    0.5978 (0.0520)\n",
      "\tF1-Score:  0.5953 (0.0369)\n",
      "\tAUROC:     0.6163 (0.0314)\n",
      "\tAUPRC:     0.6263 (0.0260)\n",
      "Alpha: 0.001, Learning Rate: constant, Max Iterations: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tAccuracy:  0.6208 (0.0330)\n",
      "\tPrecision: 0.6342 (0.0376)\n",
      "\tRecall:    0.5895 (0.0236)\n",
      "\tF1-Score:  0.6109 (0.0291)\n",
      "\tAUROC:     0.6550 (0.0221)\n",
      "\tAUPRC:     0.6548 (0.0221)\n",
      "Alpha: 0.001, Learning Rate: constant, Max Iterations: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tAccuracy:  0.6444 (0.0309)\n",
      "\tPrecision: 0.6520 (0.0307)\n",
      "\tRecall:    0.6337 (0.0561)\n",
      "\tF1-Score:  0.6416 (0.0366)\n",
      "\tAUROC:     0.6741 (0.0145)\n",
      "\tAUPRC:     0.6693 (0.0205)\n",
      "Alpha: 0.001, Learning Rate: constant, Max Iterations: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tAccuracy:  0.6458 (0.0407)\n",
      "\tPrecision: 0.6504 (0.0419)\n",
      "\tRecall:    0.6475 (0.0725)\n",
      "\tF1-Score:  0.6470 (0.0463)\n",
      "\tAUROC:     0.6833 (0.0254)\n",
      "\tAUPRC:     0.6735 (0.0236)\n",
      "Alpha: 0.001, Learning Rate: adaptive, Max Iterations: 50\n",
      "\tAccuracy:  0.5917 (0.0296)\n",
      "\tPrecision: 0.5939 (0.0257)\n",
      "\tRecall:    0.5978 (0.0520)\n",
      "\tF1-Score:  0.5953 (0.0369)\n",
      "\tAUROC:     0.6163 (0.0314)\n",
      "\tAUPRC:     0.6263 (0.0260)\n",
      "Alpha: 0.001, Learning Rate: adaptive, Max Iterations: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tAccuracy:  0.6208 (0.0330)\n",
      "\tPrecision: 0.6342 (0.0376)\n",
      "\tRecall:    0.5895 (0.0236)\n",
      "\tF1-Score:  0.6109 (0.0291)\n",
      "\tAUROC:     0.6550 (0.0221)\n",
      "\tAUPRC:     0.6548 (0.0221)\n",
      "Alpha: 0.001, Learning Rate: adaptive, Max Iterations: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tAccuracy:  0.6444 (0.0309)\n",
      "\tPrecision: 0.6520 (0.0307)\n",
      "\tRecall:    0.6337 (0.0561)\n",
      "\tF1-Score:  0.6416 (0.0366)\n",
      "\tAUROC:     0.6741 (0.0145)\n",
      "\tAUPRC:     0.6693 (0.0205)\n",
      "Alpha: 0.001, Learning Rate: adaptive, Max Iterations: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tAccuracy:  0.6458 (0.0407)\n",
      "\tPrecision: 0.6504 (0.0419)\n",
      "\tRecall:    0.6475 (0.0725)\n",
      "\tF1-Score:  0.6470 (0.0463)\n",
      "\tAUROC:     0.6833 (0.0254)\n",
      "\tAUPRC:     0.6735 (0.0236)\n",
      "Alpha: 0.01, Learning Rate: constant, Max Iterations: 50\n",
      "\tAccuracy:  0.5917 (0.0296)\n",
      "\tPrecision: 0.5939 (0.0257)\n",
      "\tRecall:    0.5978 (0.0520)\n",
      "\tF1-Score:  0.5953 (0.0369)\n",
      "\tAUROC:     0.6162 (0.0313)\n",
      "\tAUPRC:     0.6262 (0.0259)\n",
      "Alpha: 0.01, Learning Rate: constant, Max Iterations: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tAccuracy:  0.6208 (0.0330)\n",
      "\tPrecision: 0.6342 (0.0376)\n",
      "\tRecall:    0.5895 (0.0236)\n",
      "\tF1-Score:  0.6109 (0.0291)\n",
      "\tAUROC:     0.6551 (0.0221)\n",
      "\tAUPRC:     0.6548 (0.0221)\n",
      "Alpha: 0.01, Learning Rate: constant, Max Iterations: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tAccuracy:  0.6444 (0.0309)\n",
      "\tPrecision: 0.6520 (0.0307)\n",
      "\tRecall:    0.6337 (0.0561)\n",
      "\tF1-Score:  0.6416 (0.0366)\n",
      "\tAUROC:     0.6739 (0.0146)\n",
      "\tAUPRC:     0.6691 (0.0209)\n",
      "Alpha: 0.01, Learning Rate: constant, Max Iterations: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tAccuracy:  0.6458 (0.0407)\n",
      "\tPrecision: 0.6504 (0.0419)\n",
      "\tRecall:    0.6475 (0.0725)\n",
      "\tF1-Score:  0.6470 (0.0463)\n",
      "\tAUROC:     0.6832 (0.0255)\n",
      "\tAUPRC:     0.6735 (0.0238)\n",
      "Alpha: 0.01, Learning Rate: adaptive, Max Iterations: 50\n",
      "\tAccuracy:  0.5917 (0.0296)\n",
      "\tPrecision: 0.5939 (0.0257)\n",
      "\tRecall:    0.5978 (0.0520)\n",
      "\tF1-Score:  0.5953 (0.0369)\n",
      "\tAUROC:     0.6162 (0.0313)\n",
      "\tAUPRC:     0.6262 (0.0259)\n",
      "Alpha: 0.01, Learning Rate: adaptive, Max Iterations: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tAccuracy:  0.6208 (0.0330)\n",
      "\tPrecision: 0.6342 (0.0376)\n",
      "\tRecall:    0.5895 (0.0236)\n",
      "\tF1-Score:  0.6109 (0.0291)\n",
      "\tAUROC:     0.6551 (0.0221)\n",
      "\tAUPRC:     0.6548 (0.0221)\n",
      "Alpha: 0.01, Learning Rate: adaptive, Max Iterations: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tAccuracy:  0.6444 (0.0309)\n",
      "\tPrecision: 0.6520 (0.0307)\n",
      "\tRecall:    0.6337 (0.0561)\n",
      "\tF1-Score:  0.6416 (0.0366)\n",
      "\tAUROC:     0.6739 (0.0146)\n",
      "\tAUPRC:     0.6691 (0.0209)\n",
      "Alpha: 0.01, Learning Rate: adaptive, Max Iterations: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tAccuracy:  0.6458 (0.0407)\n",
      "\tPrecision: 0.6504 (0.0419)\n",
      "\tRecall:    0.6475 (0.0725)\n",
      "\tF1-Score:  0.6470 (0.0463)\n",
      "\tAUROC:     0.6832 (0.0255)\n",
      "\tAUPRC:     0.6735 (0.0238)\n",
      "Alpha: 0.1, Learning Rate: constant, Max Iterations: 50\n",
      "\tAccuracy:  0.5917 (0.0296)\n",
      "\tPrecision: 0.5939 (0.0257)\n",
      "\tRecall:    0.5978 (0.0520)\n",
      "\tF1-Score:  0.5953 (0.0369)\n",
      "\tAUROC:     0.6161 (0.0312)\n",
      "\tAUPRC:     0.6263 (0.0259)\n",
      "Alpha: 0.1, Learning Rate: constant, Max Iterations: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tAccuracy:  0.6208 (0.0330)\n",
      "\tPrecision: 0.6342 (0.0376)\n",
      "\tRecall:    0.5895 (0.0236)\n",
      "\tF1-Score:  0.6109 (0.0291)\n",
      "\tAUROC:     0.6557 (0.0218)\n",
      "\tAUPRC:     0.6554 (0.0221)\n",
      "Alpha: 0.1, Learning Rate: constant, Max Iterations: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tAccuracy:  0.6458 (0.0304)\n",
      "\tPrecision: 0.6541 (0.0312)\n",
      "\tRecall:    0.6337 (0.0561)\n",
      "\tF1-Score:  0.6425 (0.0359)\n",
      "\tAUROC:     0.6737 (0.0146)\n",
      "\tAUPRC:     0.6674 (0.0229)\n",
      "Alpha: 0.1, Learning Rate: constant, Max Iterations: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tAccuracy:  0.6444 (0.0391)\n",
      "\tPrecision: 0.6496 (0.0415)\n",
      "\tRecall:    0.6447 (0.0680)\n",
      "\tF1-Score:  0.6453 (0.0439)\n",
      "\tAUROC:     0.6825 (0.0237)\n",
      "\tAUPRC:     0.6730 (0.0239)\n",
      "Alpha: 0.1, Learning Rate: adaptive, Max Iterations: 50\n",
      "\tAccuracy:  0.5917 (0.0296)\n",
      "\tPrecision: 0.5939 (0.0257)\n",
      "\tRecall:    0.5978 (0.0520)\n",
      "\tF1-Score:  0.5953 (0.0369)\n",
      "\tAUROC:     0.6161 (0.0312)\n",
      "\tAUPRC:     0.6263 (0.0259)\n",
      "Alpha: 0.1, Learning Rate: adaptive, Max Iterations: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tAccuracy:  0.6208 (0.0330)\n",
      "\tPrecision: 0.6342 (0.0376)\n",
      "\tRecall:    0.5895 (0.0236)\n",
      "\tF1-Score:  0.6109 (0.0291)\n",
      "\tAUROC:     0.6557 (0.0218)\n",
      "\tAUPRC:     0.6554 (0.0221)\n",
      "Alpha: 0.1, Learning Rate: adaptive, Max Iterations: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tAccuracy:  0.6458 (0.0304)\n",
      "\tPrecision: 0.6541 (0.0312)\n",
      "\tRecall:    0.6337 (0.0561)\n",
      "\tF1-Score:  0.6425 (0.0359)\n",
      "\tAUROC:     0.6737 (0.0146)\n",
      "\tAUPRC:     0.6674 (0.0229)\n",
      "Alpha: 0.1, Learning Rate: adaptive, Max Iterations: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tAccuracy:  0.6444 (0.0391)\n",
      "\tPrecision: 0.6496 (0.0415)\n",
      "\tRecall:    0.6447 (0.0680)\n",
      "\tF1-Score:  0.6453 (0.0439)\n",
      "\tAUROC:     0.6825 (0.0237)\n",
      "\tAUPRC:     0.6730 (0.0239)\n",
      "Best AUROC: 0.6833 (0.0255)\n",
      "Best hyperparameters: Alpha = 0.0001, Learning Rate = constant, Max Iterations = 300\n",
      "Accuracy: Mean = 0.6458 (0.0407)\n",
      "Precision: Mean = 0.6504 (0.0419)\n",
      "Recall: Mean = 0.6475 (0.0725)\n",
      "F1-Score: Mean = 0.6470 (0.0463)\n",
      "AUROC: Mean = 0.6833 (0.0255)\n",
      "AUPRC: Mean = 0.6735 (0.0235)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, average_precision_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Initialize StratifiedKFold for cross-validation\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define hyperparameters to tune for MLP\n",
    "hidden_layer_sizes = [(6,)]  # Hidden layer size fixed at 6\n",
    "alphas = [0.0001, 0.001, 0.01, 0.1]  # Regularization parameter (alpha)\n",
    "learning_rates = ['constant', 'adaptive']  # Learning rate options\n",
    "max_iters = [50, 100, 200, 300]  # Max iterations for convergence\n",
    "\n",
    "# Track the best results\n",
    "best_auroc_mean = 0\n",
    "best_auroc_std = 0\n",
    "best_metrics = None\n",
    "best_hyperparams = None\n",
    "\n",
    "# Perform grid search over alphas, learning_rates, and max_iters\n",
    "for alpha in alphas:\n",
    "    for learning_rate in learning_rates:\n",
    "        for max_iter in max_iters:\n",
    "            print(f\"Alpha: {alpha}, Learning Rate: {learning_rate}, Max Iterations: {max_iter}\")\n",
    "            \n",
    "            # Initialize lists to store metrics for each fold\n",
    "            accuracy_scores = []\n",
    "            precision_scores = []\n",
    "            recall_scores = []\n",
    "            f1_scores = []\n",
    "            auroc_scores = []\n",
    "            auprc_scores = []\n",
    "\n",
    "            # Perform 5-fold cross-validation\n",
    "            for train_index, val_index in kf.split(X_dev, y_dev):\n",
    "                # Get train and validation data\n",
    "                X_train_fold, X_val_fold = X_dev.iloc[train_index], X_dev.iloc[val_index]\n",
    "                y_train_fold, y_val_fold = y_dev.iloc[train_index], y_dev.iloc[val_index]\n",
    "\n",
    "                # Normalize the training set and apply the same params to validation\n",
    "                scaler = StandardScaler()\n",
    "                X_train_fold_scaled = scaler.fit_transform(X_train_fold)\n",
    "                X_val_fold_scaled = scaler.transform(X_val_fold)\n",
    "\n",
    "                # Fit MLP model\n",
    "                mlp_model = MLPClassifier(hidden_layer_sizes=(6,), alpha=alpha, learning_rate=learning_rate, \n",
    "                                          max_iter=max_iter, random_state=42)\n",
    "                mlp_model.fit(X_train_fold_scaled, y_train_fold)\n",
    "\n",
    "                # Predict on validation set\n",
    "                y_val_pred = mlp_model.predict(X_val_fold_scaled)\n",
    "                y_val_prob = mlp_model.predict_proba(X_val_fold_scaled)[:, 1]  # Probabilities for positive class\n",
    "\n",
    "                # Record validation metrics\n",
    "                accuracy_scores.append(accuracy_score(y_val_fold, y_val_pred))\n",
    "                precision_scores.append(precision_score(y_val_fold, y_val_pred))\n",
    "                recall_scores.append(recall_score(y_val_fold, y_val_pred))\n",
    "                f1_scores.append(f1_score(y_val_fold, y_val_pred))\n",
    "                auroc_scores.append(roc_auc_score(y_val_fold, y_val_prob))\n",
    "                auprc_scores.append(average_precision_score(y_val_fold, y_val_prob))\n",
    "\n",
    "            # Calculate mean and standard deviation of AUROC\n",
    "            auroc_mean = np.mean(auroc_scores)\n",
    "            auroc_std = np.std(auroc_scores)\n",
    "\n",
    "            # Check if this is the best AUROC so far\n",
    "            if auroc_mean > best_auroc_mean:\n",
    "                best_auroc_mean = auroc_mean\n",
    "                best_auroc_std = auroc_std\n",
    "                best_metrics = {\n",
    "                    'accuracy': (np.mean(accuracy_scores), np.std(accuracy_scores)),\n",
    "                    'precision': (np.mean(precision_scores), np.std(precision_scores)),\n",
    "                    'recall': (np.mean(recall_scores), np.std(recall_scores)),\n",
    "                    'f1_score': (np.mean(f1_scores), np.std(f1_scores)),\n",
    "                    'auroc': (auroc_mean, auroc_std),\n",
    "                    'auprc': (np.mean(auprc_scores), np.std(auprc_scores))\n",
    "                }\n",
    "                best_hyperparams = {'alpha': alpha, 'learning_rate': learning_rate, 'max_iter': max_iter}\n",
    "\n",
    "            # Report mean and standard deviation of cross-validation metrics\n",
    "#             print(f\"\\tAccuracy:  {np.mean(accuracy_scores):.4f} ({np.std(accuracy_scores):.4f})\")\n",
    "#             print(f\"\\tPrecision: {np.mean(precision_scores):.4f} ({np.std(precision_scores):.4f})\")\n",
    "#             print(f\"\\tRecall:    {np.mean(recall_scores):.4f} ({np.std(recall_scores):.4f})\")\n",
    "#             print(f\"\\tF1-Score:  {np.mean(f1_scores):.4f} ({np.std(f1_scores):.4f})\")\n",
    "#             print(f\"\\tAUROC:     {auroc_mean:.4f} ({auroc_std:.4f})\")\n",
    "#             print(f\"\\tAUPRC:     {np.mean(auprc_scores):.4f} ({np.std(auprc_scores):.4f})\")\n",
    "\n",
    "# Print the best results\n",
    "print(f\"Best AUROC: {best_metrics['auroc'][0]:.4f} ({best_metrics['auroc'][1]:.4f})\")\n",
    "print(f\"Best hyperparameters: Alpha = {best_hyperparams['alpha']}, Learning Rate = {best_hyperparams['learning_rate']}, Max Iterations = {best_hyperparams['max_iter']}\")\n",
    "print(f\"Accuracy: Mean = {best_metrics['accuracy'][0]:.4f} ({best_metrics['accuracy'][1]:.4f})\")\n",
    "print(f\"Precision: Mean = {best_metrics['precision'][0]:.4f} ({best_metrics['precision'][1]:.4f})\")\n",
    "print(f\"Recall: Mean = {best_metrics['recall'][0]:.4f} ({best_metrics['recall'][1]:.4f})\")\n",
    "print(f\"F1-Score: Mean = {best_metrics['f1_score'][0]:.4f} ({best_metrics['f1_score'][1]:.4f})\")\n",
    "print(f\"AUROC: Mean = {best_metrics['auroc'][0]:.4f} ({best_metrics['auroc'][1]:.4f})\")\n",
    "print(f\"AUPRC: Mean = {best_metrics['auprc'][0]:.4f} ({best_metrics['auprc'][1]:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "36491689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.7167\n",
      "Precision on test set: 0.7222\n",
      "Recall on test set: 0.7143\n",
      "F1-Score on test set: 0.7182\n",
      "AUROC on test set: 0.7527\n",
      "AUPRC on test set: 0.7667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oliviazhang/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# After determining the best hyperparameters from cross-validation:\n",
    "best_alpha = best_hyperparams['alpha']\n",
    "best_learning_rate = best_hyperparams['learning_rate']\n",
    "best_max_iter = best_hyperparams['max_iter']\n",
    "\n",
    "# Normalize the entire development set and the test set\n",
    "scaler = StandardScaler()\n",
    "X_dev_scaled = scaler.fit_transform(X_dev)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Fit the MLP model on the entire development set using the best hyperparameters\n",
    "mlp_model = MLPClassifier(hidden_layer_sizes=(6,), alpha=best_alpha, learning_rate=best_learning_rate, \n",
    "                          max_iter=best_max_iter, random_state=42)\n",
    "mlp_model.fit(X_dev_scaled, y_dev)\n",
    "\n",
    "# Predict on the test set\n",
    "y_test_pred = mlp_model.predict(X_test_scaled)\n",
    "y_test_prob = mlp_model.predict_proba(X_test_scaled)[:, 1]  # Probabilities for the positive class\n",
    "\n",
    "# Evaluate the test set metrics\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "precision_test = precision_score(y_test, y_test_pred)\n",
    "recall_test = recall_score(y_test, y_test_pred)\n",
    "f1_test = f1_score(y_test, y_test_pred)\n",
    "auroc_test = roc_auc_score(y_test, y_test_prob)\n",
    "auprc_test = average_precision_score(y_test, y_test_prob)\n",
    "\n",
    "# Print the test set performance\n",
    "print(f\"Accuracy on test set: {accuracy_test:.4f}\")\n",
    "print(f\"Precision on test set: {precision_test:.4f}\")\n",
    "print(f\"Recall on test set: {recall_test:.4f}\")\n",
    "print(f\"F1-Score on test set: {f1_test:.4f}\")\n",
    "print(f\"AUROC on test set: {auroc_test:.4f}\")\n",
    "print(f\"AUPRC on test set: {auprc_test:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40a51b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
